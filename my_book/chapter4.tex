\section{Interpretation of $\Psi$}

Given that we can solve Schr\"odinger's equation to generate a wave function
$\Psi(x, t)$, the most natural first question to ask is ``What is $\Psi$?". As
the wave function for a particle is generally complex, $\Psi$ cannot be
associated with measurements. Instead, in the case of a wave function spread
over a range of possible coordinates $x$, we identify the product of $\Psi(x,
t)$ with its complex conjugate, $\Psi^*(x, t)$, as the \textit{position
probability density}. 

\[
P(x, t) = \text{ position probability density } = \Psi^*(x, t)\Psi(x, t)
= |\Psi(x, t)|^2
\] \vspace{3px}

Therefore, 

\[
dP(x, t) \equiv |\Psi(x, t)|^2\,dx \] \vspace{3px}

is the probability of finding the particle in a region $dx$ around $x$ if the
measurement is made at time $t$. \\ 

Generally this is the provided definition for what $\Psi(x, t)$ is -- the
function that when multiplied by its complex conjugate produces the position
probability density of the particle it represents. Later however, when we
encounter Dirac notation, we will learn of a much more intuitive and rigorous
definition for $\Psi$. But for now, position probability density works. 

Now since $|\Psi(x, t)|^2$ is a probability density, it follows that the
integral of $|\Psi(x, t)|^2$ over all $x$ must be 1 -- the particle has to
exist somewhere! Therefore, we require the \textit{normalization condition} of
the wave function: 

\begin{align} \label{eq:normalization}
  \int_\Omega |\Psi(x, t)|^2 \, dx = 1
\end{align}

where the integral extends over the domain $\Omega$, where the wave function is
defined. If we are discussing a free particle, it may be all of space,
$-\infty < x < \infty$. Or perhaps if we consider a particle confined within
a potential well with infinitely high walls where the width of the well is $a$
-- a problem we consider \textit{very} soon, then the relevant
boundaries of the integral may be $-a/2 < x < a/2$. Regardless of the
situation, the particle has to exist somewhere, so we must require the
normalization condition for all particles. 

Of course, wave functions $\Psi(x, t)$ we obtain from solving Schrodinger's
Equation have in general some arbitrary normalization. In that case we quantum
mechanics have to fix that situation. If when we compute 

\[
\int_D |\Psi(x, t)|^2 \, dx = N
\] \vspace{3px}

Then we form the normalized wave function $\Psi_N(x, t)$ 
\begin{align} \label{eq:normalized wave function}
  \Psi_N(x, t) \equiv \frac{1}{\sqrt{N}} \Psi(x, t)
\end{align}

The wave function we use is the normalized one, $\Psi_N(x, t)$. But wait!
suppose I normalize some way function at time $t=0$. How do I know it
\textit{stays} normalized as time passes and $\Psi(x, t)$ evolves? Luckily,
Schr\"odinger's Equation has the remarkable property that it \textit{preserves}
the normalization of the wave function. If this wasn't true, building a working
theory of Quantum Mechanics would be a nightmare (at least, more of
a nightmare). Because of how important this normalization-preservation fact is,
I provide a proof, which utilizes the Schr\"odinger equation. We start by
expanding the following time derivative: 

\begin{align} \label{eq:normproof1}
  \frac{d }{d t} \int_{-\infty}^{\infty} |\Psi(x, t)|^2 \, dx
  = \int_{-\infty}^{\infty} \frac{\partial }{\partial t} |\Psi(x, t)|^2 \, dx.        
\end{align}\vspace{3px}

By the product rule, 

\begin{align} \label{eq:normproof2}
  \frac{\partial }{\partial t} |\Psi(x, t)|^2 = \frac{\partial }{\partial t}
  [\Psi^*(x, t)\Psi(t)]= \Psi^* \frac{\partial \Psi}{\partial t}
  + \frac{\partial \Psi^*}{\partial t} \Psi.
\end{align}\vspace{3px}

Now the Schr\"odinger equation states 

\begin{align} \label{eq:normproof3}
\frac{\partial \Psi}{\partial t} = \frac{i\hbar}{2m} \frac{\partial^2
\Psi}{\partial x^2} - \frac{i}{\hbar}V\Psi,    
\end{align}\vspace{3px}

and hence also (taking the complex conjugate of Equation \ref{eq:normproof3}, 

\begin{align} \label{eq:normproof4}
  \frac{\partial \Psi^*}{\partial t} = -\frac{i\hbar}{2m} \frac{\partial^2
  \Psi^*}{\partial x^2} + \frac{i}{\hbar} V\Psi^*.
\end{align}\vspace{3px}

Therefore, substituting in Equation \ref{eq:normproof3} and Equation
\ref{eq:normproof4} into Equation \ref{eq:normproof2}, 

\begin{align} \label{eq:normproof5}
  \frac{\partial }{\partial t} |\Psi|^2 = \frac{i\hbar}{2m}\left( \Psi^*
  \frac{\partial^2 \Psi}{\partial x^2} - \frac{\partial^2 \Psi^*}{\partial x^2}
\Psi\right) = \frac{\partial }{\partial x} \left[ \frac{i\hbar}{2m} \left(
  \Psi^* \frac{\partial \Psi}{\partial x} - \frac{\partial \Psi^*}{\partial x}
\Psi\right) \right].  
\end{align}\vspace{3px}


The integral in Equation \ref{eq:normproof1} can now be evaluated explicitly: 

\[
\frac{d }{d t} \int_{-\infty}^{\infty} |\Psi(x, t)|^2 \, dx
= \frac{i\hbar}{2m}\left( \Psi^* \frac{\partial \Psi}{\partial x}
- \frac{\partial \Psi^*}{\partial x} \Psi \right) \Bigg|_{-\infty}^\infty 
\] \vspace{3px}

And since $\Psi(x,t) \rightarrow 0$ as $x \rightarrow \pm \infty$ -- otherwise
the wave function would not be normalizable -- it follows that 

\begin{align} \label{eq:normproof6}
  \frac{d }{d t} \int_{-\infty}^{\infty} |\Psi(x, t)|^2 \, dx = 0.
\end{align}\vspace{3px}

Therefore, the integral is independent of time -- if $\Psi$ is normalized at
$t = 0$, it  \textit{stays} normalized for all future time. 

\section{Expected Value \& Variance}

As $|\Psi(x, t)|^2$ represents a probability distribution, we can determine
properties of this distribution by evaluating various moments of the outcome
variable. The simplest would be the zeroth moment, defined here as the
unweighted moment, which just checks that 

\begin{align*} \label{}
  \langle 1 \rangle \equiv \int_\Omega 1|\Psi(x, t)|^2 \, dx = 1      
\end{align*}\vspace{3px}

The next is the first moment -- called the expected value (basically the mean)
-- 

\begin{align} \label{eq:expvalue}
  \langle x \rangle \equiv \int_\Omega x |\Psi(x, t)|^2 \, dx
\end{align}  

If one measured the position $x$ of a particle with an identical wave function
$\Psi(x, t)$, and recorded its value an infinite amount of times. The average
of the recorded measurements is the mean, or expected value. Therefore,
$\langle x \rangle $ is the most-likely $x$ to come as an outcome of measuring
$\Psi(x, t)$. This intuitively makes sense if you think of Equation \ref{eq:expvalue} as
an infinite discrete sum $\langle x \rangle = \sum_N x_N |\Psi(x, t)|^2$. We
multiply each possible outcome $x_N$ by the likelihood of this outcome
$|\Psi(x, t)|^2$, and afterward sum up all our values, producing a `weighted
average,' or the mean/expected value. \\

The second moment of most interest is the variance. The second moment about the
mean 

\begin{align*} \label{}
  \langle x - \langle x \rangle  \rangle ^2 \equiv \int_\Omega (x - \langle
  x \rangle )^2 |\Psi(x, t)|^2 \, dx
\end{align*}\vspace{3px}

And since $\langle x \rangle $ is just a number, 

\begin{align*}
  \langle x - \langle x \rangle  \rangle ^2 = \langle x^2 \rangle - \langle
  x \rangle ^2 \geq 0
\end{align*}\vspace{3px}

So knowledge of the first and second moments 

\begin{align*}
  \langle x \rangle = \int_\Omega x|\Psi(x, t)|^2 \, dx \qquad \langle x^2
  \rangle \int_\Omega x^2 |\Psi(x, t)|^2 \, dx
\end{align*}\vspace{3px}

allows one to calculate the variance. The standard deviation 

\begin{align*}
  \sigma \equiv \sqrt{\langle x - \langle x \rangle  \rangle ^2}
\end{align*}

For distributions approximately Gaussian, the probability that an outcome will
be within $1\sigma$ of the mean is about $2/3$rds. 

\section{Measurement \& Collapse of $\Psi$}

A pitcher threw a fastball, and the hitter land off. The ball was caught by
the catcher. But the umpire said nothing. Finally the batter said, ``Well what
was it, a ball or a strike?" The umpire replied ``It ain't nothing til I call
it." This is a pretty good description of the relationship of wave functions to
measurement. 

The position of an electron may be described by a probability $|\Psi(x, t)|^2$
that is nonzero over some range in $x$, but when a measurement is done, the
electron's location will be found to be some definite outcome $x_1$. If
a million measurement experiments were prepared, all with the same identical initial
conditions, each would likely yield a definite value on making a measurement
producing $\{x_1, x_2, \cdots, x_{1000000}\}$. The individual experiments
likely yield different results, but Quantum Mechanics tells us that if we look
at the \textit{distribution} of measurements, it will match $|\Psi(x, t)|^2$.
This is known as the Copenhagen interpretation of Quantum Mechanics --
$|\Psi(x, t)|^2$ predicts the probabilities of all possible outcomes $x_i$, but
does not tell us the specific value $x_i$ that emerges from a specific
measurement.

This implies something interesting about measurement -- it impacts the wave
function. If one makes a measurement producing the result $x_1$ at some time
$t$, then repeats the measurement immediately afterwards, at some time
$t+\delta t$, then the same outcome $x_2 \sim x_1$ (within some small $\delta
x$ ) will be obtained. The first measurement impacted the wave function,
\textit{collapsing} it, greatly narrowing the possibilities.\\

\begin{figure}[htp]
\begin{subfigure}[b]{.49\linewidth}
\centering
\includegraphics[width=\linewidth]{gaussian1.pdf}\label{fig_1a}
\caption{Initial $|\Psi(x, t)|^2$}
\end{subfigure}
\begin{subfigure}[b]{.49\linewidth}
\centering
\includegraphics[width=\linewidth]{gaussian2.pdf}\label{fig_1b}
\caption{$|\Psi(x, t + \delta t)|^2$ after measuring $x \sim -x_i$}
\end{subfigure}%
\caption{Performing a measurement collapses the wave function. Here, we
consider that a measurement produces a value $x \sim -x_i$ for the particle. As
a result the final position probability density is very narrow around $x = -x_i$.}
\end{figure} 

This intuitively makes sense. If we measure a particles position and get some
value $x_i$, and if we immediately perform another measurement within some  $\delta t$,
the particle could not have moved \textit{that much} from its initial position
$x_i$ in such a small $\delta t$. This means the position probability  density
becomes more narrow and localized around $x \sim x_i$. How narrow the $|\Psi(x, t+\delta t)|^2$
becomes after measurement depends on how precisely the measurement was done. We have also already mentioned the uncertainty principle, the notion that the
better one defines $x$, the broader the spread in $p$. So this new, more
localized, wave packet, very narrow in $x$, will contain, as a result of the
measurement, many high-momentum components -- a really wide spread of the
`momentum probability density'. 

\begin{figure}[H]
\begin{subfigure}[b]{.49\linewidth}
\centering
\includegraphics[width=\linewidth]{gaussian2.pdf}\label{fig_1c}
\caption{$|\Psi(x, t + \delta t)|^2$ }
\end{subfigure}
\begin{subfigure}[b]{.49\linewidth}
\centering
\includegraphics[width=\linewidth]{gaussian3.pdf}\label{fig_1d}
\caption{ $|\Phi(p, t + \delta t)|^2$}
\end{subfigure}%
\caption{A narrow $|\Psi(x, t)|^2$  (a) implies a very spread $|\Phi(p, t)|^2$ (b). Since coordinate-space wave packets and momentum-space packets are
inverse Fourier transforms of one another, $\Psi(x, t)$ and $\Phi(p, t)$ are inverse F.T's
of one another. Note from this moment on $\Psi$ refers to coordinate-space and
$\Phi$ refers to momentum-space.}
\end{figure}

Therefore, since a narrower coordinate-space wave packet contains many
high-momentum and therefore high-velocity momentum-space wave packets, the
particle moves \textit{very} fast after an initial measurement. This means that
the \textit{narrower $|\Psi(x, t)|^2$,} after measurement, the \textit{faster
$|\Psi(x, t)|^2$ will spread}. 

The more precise the measurement of $x_1$, the larger the spread
in momentum-space components -- and the faster $|\Psi(x, t)|^2$ will spread.
Thus if you do not make the second measurement immediately,
but wait some significant time, you likely will not get an $x_2$ very near
$x_1$. \\

This is not classical mechanics, but a new theory guided by intuitive rules,
and they are easy for us to embrace. The ideas are quite beautiful. We have not
yet actually solved any Quantum Mechanics problems up to this point, but that
is fine. If you are beginning to \textbf{\textit{intuitively understand}} how
the subatomic world works, that intuition will guide you as you begin to solve
problems. Quantum Mechanics makes sense! 

\section{Expectation values of Operators}

In our discussion of probability distributions and moments -- means and
standard deviations -- we emphasized their importance in characterizing
distribution functions, but the  discussion directly above about measurement
now takes us beyond the math, into the physics. If the outcome of our
experiment is a particle's position, and if we repeat the experiment with
identical initial conditions a thousand times, then we have already shown how
the mean of those position outcomes relate to the wave function

\[
\langle x \rangle = \int_{-\infty}^{\infty} x |\Psi(x, t)|^2 \, dx
\] \vspace{3px}

In fact, we can rewrite this statement in a slightly different way that
corresponds better to the concept of measurement, 

\[
\langle \hat{x} \rangle \equiv \int_{-\infty}^{\infty} \Psi^*(x, t) \,\hat{x}\,
\Psi(x, t) \, dx = \int_{-\infty}^{\infty} \Psi^*(x, t) \, x \, \Psi(x, t)\, dx
= \int_{-\infty}^{\infty} x |\Psi(x, t)|^2 \, dx
\] \vspace{3px}

It may seem like semantics at this point, but think of $\hat{x}$ as an operator
that \textit{interrogates} the wave function (the process of taking
a measurement), and $x$ as the \textit{outcome} of the interrogation (the
experimental result). \\

The momentum operator provides another example of the distinction drawn above
-- interrogation vs. outcome. We deduced the momentum operator from our
discussion of the Schr\"odinger equation in Equation \ref{eq:momentum}.
Therefore, 

\begin{align} \label{}
  \langle \hat{p} \rangle \equiv \int_{-\infty}^{\infty} \Psi^*(x, t)
  \,\hat{p}\, \Psi(x, t) \, dx = \int_{-\infty}^{\infty} \Psi^*(x, t) \left(
  \frac{\hbar}{i} \frac{\partial }{\partial x}  \right) \Psi(x, t) \, dx
\end{align}\vspace{3px}


Here we can write out the needed interrogation operator for our
coordinate-space wave function, but we can't actually evaluate the outcome if
we do not have an explicit form for our wave function. But if someone tells you
that $\Psi(x, t)$ is a normalized plane wave confined to a 1D ``volume" of
length $L$, then you can carry out the interrogation to obtain the outcome

\[ \Psi(x, t) = \frac{1}{\sqrt{L}}e^{i(p_0  x - E_0 t)/\hbar} \text{ where
}  E_0 = E_0(p) = p_0^2 / 2m \quad \Rightarrow \]
\begin{align*}
  \int_{-L/2}^{L/2} \psi^*(x, t) \left( \frac{\hbar}{i} \frac{\partial
  }{\partial x}  \right) \Psi(x, t) \, dx = \int_{-L/2}^{L/2} \Psi^*(x, t) \,
  p_0 \, \Psi(x,t) \, dx = p_0 \int_{-L/2}^{L/2} |\Psi(x, t)|^2 \, dx = p_0
\end{align*}\vspace{3px}

I should stress that $p_0$ is just a number in the work above -- a parameter
defining the wave function. 

\subsection{Time Evolution of Operator Expectation Values}

Consider an operator $\hat{x}$ or $\hat{p}$ that itself does not depend on
time, but where the wave function it acts on \textit{is} evolving in time. This
would be the case, for example, of a wave packet moving with some velocity.
Operator expectation values would then evolve in time because of the wave
function changing. Following the same steps we employed to demonstrate that
normalizations do not evolve in time, we get 

\begin{align*}
  \frac{d \langle \hat{x} \rangle }{d t} &= \frac{i\hbar}{2m}
  \int_{-\infty}^{\infty} x \frac{\partial }{\partial x}  \left[ \Psi^*(x, t)
    \frac{\partial \Psi(x, t)}{\partial x}  - \frac{\partial \Psi^*(x,
  t)}{\partial x} \Psi(x, t) \right] \, dx \\ 
  &= -\frac{i\hbar}{2m}\int_{-\infty}^{\infty} \left[ \Psi^*(x, t)
  \frac{\partial \Psi(x, t)}{\partial x}  - \frac{\partial \Psi^*(x,
t)}{\partial x} \Psi(x, t) \right] \, dx \\ 
  &= -\frac{i\hbar}{m} \int_{-\infty}^{\infty} \Psi^*(x, t) \frac{\partial
  }{\partial x} \Psi(x, t) \, dx = \frac{1}{m} \int_{-\infty}^{\infty}
  \Psi^*(x, t) \left( \frac{\hbar}{i} \frac{\partial }{\partial x}  \right)
  \Psi(x, t) \, dx
\end{align*}\vspace{3px}

where we integrated by parts to get the second step, assuming that the wave
packet vanishes at the boundaries; and then integrated by parts again in the
third line. Thus we find 

\[
\frac{d \langle \hat{x} \rangle }{d i}  = \frac{\langle \hat{p} \rangle }{m}
\equiv \langle \hat{v} \rangle 
\] \vspace{3px}

One can repeat the steps above starting with  $ \frac{d \langle \hat{p} \rangle
}{d t} $ to find 

\[
\frac{d \langle \hat{p} \rangle }{d t} = \langle - \frac{\partial V}{\partial x}  \rangle 
\] \vspace{3px}

which we recognize as Newton's second law. These two results constitute 
\vspace{3px}
\begin{mainbox}{Ehrenfest's Theorem}
  An example of the correspondence principle -- expectation values obey the
  corresponding classical laws of motion. 
\end{mainbox}
\vspace{3px}

\subsection{The Uncertainty Principle}  

If you have taken linear algebra, you may have seen the Cauchy-Schwarz
Inequality. If $\vec{u}$ and $\vec{v}$ are two vectors in some vector space,
then 

\[
\vec{u}\cdot \vec{u} \vec{v} \cdot \vec{v} \geq |\vec{u}\cdot \vec{v}|^2
\] \vspace{3px}

For functions there is an analogous Cauchy-Schwarz Identity

\[
  \int |f(x)|^2 \, dx \int |g(x)|^2 \, dx \geq \left| \int f^*(x) g(x) \, dx
  \right|^2
\] \vspace{3px}

We make the following definitions: 

\[
  (\sigma_x)^2 \equiv \langle (\hat{x} - \langle \hat{x} \rangle )^2 \rangle
  = \langle \hat{x}^2 \rangle - \langle \hat{x} \rangle ^2
  \qquad (\sigma_p)^2 \equiv \langle (\hat{p} - \langle \hat{p} \rangle )^2
  \rangle = \langle \hat{p}^2 \rangle - \langle \hat{p} \rangle ^2
\] \vspace{3px}

and the following substitutions into the Cauchy-Schwarz Identity 

\[
f(x) \rightarrow (\hat{x} - \langle \hat{x} \rangle ) \Psi(x, t) \quad \text{
and } \quad g(x) \rightarrow (\hat{p} - \langle \hat{p} \rangle )\Psi(x, t)
\] \vspace{3px}

The LHS is seen to be 

\[
  (\sigma_x)^2(\sigma_y)^2
\] \vspace{3px}

while the RHS can be manipulated into the form 

\begin{align*}
  &\frac{1}{4}\left| \int \psi^*(x, t) [(\hat{x} - \langle \hat{x} \rangle
    )(\hat{p} - \langle \hat{p} \rangle ) - (\hat{p} - \langle \hat{p} \rangle
    )(\hat{x} - \langle \hat{x} \rangle )] \Psi(x, t) \, dx \right|^2 \\ 
  +&\frac{1}{4}\left| \int \psi^*(x, t) [(\hat{x} - \langle \hat{x} \rangle
    )(\hat{p} - \langle \hat{p} \rangle ) + (\hat{p} - \langle \hat{p} \rangle
    )(\hat{x} - \langle \hat{x} \rangle )] \Psi(x, t) \, dx \right|^2 \\
  \geq &\frac{1}{4}\left| \int \psi^*(x, t) [(\hat{x} - \langle \hat{x} \rangle
    )(\hat{p} - \langle \hat{p} \rangle ) - (\hat{p} - \langle \hat{p} \rangle
    )(\hat{x} - \langle \hat{x} \rangle )] \Psi(x, t) \, dx \right|^2
\end{align*}\vspace{3px}

as we have the sum of two positive definite terms. Now by direct evaluation you
can show 

\[
[(\hat{x} - \langle \hat{x} \rangle )(\hat{p} - \langle \hat{p} \rangle
) - (\hat{p} - \langle \hat{p} \rangle )(\hat{x} - \langle \hat{x} \rangle )]
= i\hbar
\] \vspace{3px}

Thus we obtain

\[
  (\sigma_x)^2 (\sigma_p)^2 \geq \frac{\hbar^2}{4}
\] \vspace{3px}

So we retrieve the uncertainty principle

\[
\sigma_x\sigma_p \geq \frac{\hbar}{2}.
\] \vspace{3px}

This uncertainty relation also has an analog in \textit{energy} and
\textit{time}. We consider the kinetic energy for an arbitrary wave packet

\[
\Delta E = \Delta \frac{p^2}{2m} = \frac{p}{m} \Delta p
\] \vspace{3px}

Hence, an uncertainty in momentum implies an uncertainty in energy. Now
consider a measurement of the time it takes for the wave packet to pass
a monitor that we setup to measure its passage. However, since the width of the
packet is uncertain by $\Delta x$, there must be a corresponding uncertainty in
the time measurement, 

\[
\Delta t = \frac{\Delta x}{v} = \frac{m}{p}\Delta x \geq
\frac{m}{p}\frac{h}{2\Delta p} = \frac{h}{2}\frac{1}{\Delta E}
\] \vspace{3px}

Therefore, rearranging yields

\[
\Delta E \Delta t \geq \frac{\hbar}{2} 
\] \vspace{3px}


